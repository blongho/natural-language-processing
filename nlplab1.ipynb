{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/blongho/natural-language-processing/blob/master/nlplab1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "tested-office",
      "metadata": {
        "id": "tested-office"
      },
      "source": [
        "## This is laboration exercise 1 Basic NLP processing in the Natural Language Processing - NLP course by Hercules Dalianis"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# if check if we are in colab\n",
        "import sys\n",
        "IN_COLAB = 'google.colab' in sys.modules"
      ],
      "metadata": {
        "id": "sfQVc7AnCKT6"
      },
      "id": "sfQVc7AnCKT6",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if IN_COLAB:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive/')\n",
        "  #!ls \"/content/drive/My Drive\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XAsrnpmg_ab4",
        "outputId": "01a014f6-8ef4-45e7-e835-2f6fffce113f"
      },
      "id": "XAsrnpmg_ab4",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "antique-alignment",
      "metadata": {
        "id": "antique-alignment"
      },
      "outputs": [],
      "source": [
        "# Start Jupiter notebook or your Python interpreted and open the \n",
        "# Corpus file\n",
        "if IN_COLAB:\n",
        "  corpusFilePointer = open(\"/content/drive/My Drive/notebooks/nlp/lab1/BBC_politics_business.txt\")\n",
        "else:\n",
        "  corpusFilePointer = open(\"BBC_politics_business.txt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "characteristic-article",
      "metadata": {
        "id": "characteristic-article"
      },
      "source": [
        "Download the BBB Politics and Business corpus \n",
        "http://people.dsv.su.se/hercules/BBC_politics_business.txt\n",
        "and put in a folder called NLP-lab1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "handed-barrier",
      "metadata": {
        "id": "handed-barrier"
      },
      "outputs": [],
      "source": [
        "corpusText = corpusFilePointer.read()\n",
        "corpusFilePointer.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "surface-niger",
      "metadata": {
        "id": "surface-niger",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a41d383a-bc89-46a8-ab32-3205aa7bf0cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading collection 'all'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package abc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/abc.zip.\n",
            "[nltk_data]    | Downloading package alpino to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/alpino.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping\n",
            "[nltk_data]    |       taggers/averaged_perceptron_tagger_ru.zip.\n",
            "[nltk_data]    | Downloading package basque_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/basque_grammars.zip.\n",
            "[nltk_data]    | Downloading package biocreative_ppi to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/biocreative_ppi.zip.\n",
            "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/bllip_wsj_no_aux.zip.\n",
            "[nltk_data]    | Downloading package book_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/book_grammars.zip.\n",
            "[nltk_data]    | Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown.zip.\n",
            "[nltk_data]    | Downloading package brown_tei to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown_tei.zip.\n",
            "[nltk_data]    | Downloading package cess_cat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_cat.zip.\n",
            "[nltk_data]    | Downloading package cess_esp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_esp.zip.\n",
            "[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/chat80.zip.\n",
            "[nltk_data]    | Downloading package city_database to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/city_database.zip.\n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
            "[nltk_data]    | Downloading package comparative_sentences to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/comparative_sentences.zip.\n",
            "[nltk_data]    | Downloading package comtrans to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2002.zip.\n",
            "[nltk_data]    | Downloading package conll2007 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package crubadan to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/crubadan.zip.\n",
            "[nltk_data]    | Downloading package dependency_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dependency_treebank.zip.\n",
            "[nltk_data]    | Downloading package dolch to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dolch.zip.\n",
            "[nltk_data]    | Downloading package europarl_raw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/europarl_raw.zip.\n",
            "[nltk_data]    | Downloading package extended_omw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/extended_omw.zip.\n",
            "[nltk_data]    | Downloading package floresta to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/floresta.zip.\n",
            "[nltk_data]    | Downloading package framenet_v15 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v15.zip.\n",
            "[nltk_data]    | Downloading package framenet_v17 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v17.zip.\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data]    | Downloading package ieer to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ieer.zip.\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data]    | Downloading package indian to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/indian.zip.\n",
            "[nltk_data]    | Downloading package jeita to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package kimmo to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/kimmo.zip.\n",
            "[nltk_data]    | Downloading package knbc to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package large_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/large_grammars.zip.\n",
            "[nltk_data]    | Downloading package lin_thesaurus to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/lin_thesaurus.zip.\n",
            "[nltk_data]    | Downloading package mac_morpho to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mac_morpho.zip.\n",
            "[nltk_data]    | Downloading package machado to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package masc_tagged to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n",
            "[nltk_data]    | Downloading package moses_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/moses_sample.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mte_teip5.zip.\n",
            "[nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/mwa_ppdb.zip.\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/names.zip.\n",
            "[nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nonbreaking_prefixes.zip.\n",
            "[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nps_chat.zip.\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/omw.zip.\n",
            "[nltk_data]    | Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/omw-1.4.zip.\n",
            "[nltk_data]    | Downloading package opinion_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/opinion_lexicon.zip.\n",
            "[nltk_data]    | Downloading package panlex_swadesh to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package paradigms to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/paradigms.zip.\n",
            "[nltk_data]    | Downloading package pe08 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pe08.zip.\n",
            "[nltk_data]    | Downloading package perluniprops to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/perluniprops.zip.\n",
            "[nltk_data]    | Downloading package pil to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pil.zip.\n",
            "[nltk_data]    | Downloading package pl196x to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pl196x.zip.\n",
            "[nltk_data]    | Downloading package porter_test to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/porter_test.zip.\n",
            "[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ppattach.zip.\n",
            "[nltk_data]    | Downloading package problem_reports to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/problem_reports.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_1 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_1.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_2 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_2.zip.\n",
            "[nltk_data]    | Downloading package propbank to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package pros_cons to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pros_cons.zip.\n",
            "[nltk_data]    | Downloading package ptb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ptb.zip.\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data]    | Downloading package qc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/qc.zip.\n",
            "[nltk_data]    | Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/rslp.zip.\n",
            "[nltk_data]    | Downloading package rte to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/rte.zip.\n",
            "[nltk_data]    | Downloading package sample_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/sample_grammars.zip.\n",
            "[nltk_data]    | Downloading package semcor to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package senseval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/senseval.zip.\n",
            "[nltk_data]    | Downloading package sentence_polarity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentence_polarity.zip.\n",
            "[nltk_data]    | Downloading package sentiwordnet to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentiwordnet.zip.\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
            "[nltk_data]    | Downloading package sinica_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sinica_treebank.zip.\n",
            "[nltk_data]    | Downloading package smultron to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/smultron.zip.\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package spanish_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/spanish_grammars.zip.\n",
            "[nltk_data]    | Downloading package state_union to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/state_union.zip.\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data]    | Downloading package subjectivity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/subjectivity.zip.\n",
            "[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/swadesh.zip.\n",
            "[nltk_data]    | Downloading package switchboard to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/switchboard.zip.\n",
            "[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping help/tagsets.zip.\n",
            "[nltk_data]    | Downloading package timit to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/timit.zip.\n",
            "[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/toolbox.zip.\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data]    | Downloading package udhr to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr.zip.\n",
            "[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr2.zip.\n",
            "[nltk_data]    | Downloading package unicode_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/unicode_samples.zip.\n",
            "[nltk_data]    | Downloading package universal_tagset to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/universal_tagset.zip.\n",
            "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package vader_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package verbnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet.zip.\n",
            "[nltk_data]    | Downloading package verbnet3 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet3.zip.\n",
            "[nltk_data]    | Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/webtext.zip.\n",
            "[nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/wmt15_eval.zip.\n",
            "[nltk_data]    | Downloading package word2vec_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/word2vec_sample.zip.\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data]    | Downloading package wordnet2021 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet2021.zip.\n",
            "[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet31.zip.\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/words.zip.\n",
            "[nltk_data]    | Downloading package ycoe to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ycoe.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection all\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# Import NLTK library\n",
        "#!pip install nltk\n",
        "import nltk\n",
        "nltk.download('all')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "harmful-theta",
      "metadata": {
        "id": "harmful-theta"
      },
      "outputs": [],
      "source": [
        "# Tokenize the Corpus using the nltk.word_tokenize()\n",
        "tokens = nltk.word_tokenize(corpusText)\n",
        "#tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "fixed-madison",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fixed-madison",
        "outputId": "5581fa0c-af81-4794-f763-bce25b641406"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "84335"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# 1)\n",
        "# Calculate the number of tokens in the corpus. \n",
        "# Think about it as length of a list.\n",
        "num_of_tokens = len(tokens)\n",
        "num_of_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "cosmetic-blocking",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cosmetic-blocking",
        "outputId": "1aae5cc0-6374-476c-8007-6da2f1c189c4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9763"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# 2)\n",
        "# Calculate the number of unique tokens (types) there are in the corpus. \n",
        "# \"This is a token. This is another token.\" There are two occurancies of \"token\" in the previous\n",
        "# string but one type \"token\".\n",
        "# To calculate the types think about the set() function\n",
        "token_set = set(tokens)\n",
        "len(token_set)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "entertaining-concord",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "entertaining-concord",
        "outputId": "422f42af-0184-4841-fa92-81830f2e0cf6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stop words  lenght 179 \n",
            "Stopwords are\n",
            " ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
          ]
        }
      ],
      "source": [
        "# Import the predefined stopwords in NLTK\n",
        "from nltk.corpus import stopwords\n",
        "#nltk.download('stopwords')\n",
        "stop_words = stopwords.words('english')\n",
        "\n",
        "# 3)\n",
        "# How many stopword are there in the stop word list? \n",
        "# Are this few or many stop words, can you think about \n",
        "# other stopwords?\n",
        "#print(\"There are \", len(stop_words) , \" words in the stopwords list\")\n",
        "print(\"Stop words  lenght\",len(stop_words), \"\\nStopwords are\\n\", stop_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "known-memphis",
      "metadata": {
        "id": "known-memphis"
      },
      "outputs": [],
      "source": [
        "# Write a Python function that filters out the stopwords from \n",
        "# the BBC corpus\n",
        "def remove_stopwords(corpus: list):\n",
        "    return [x for x in corpus if x not in stop_words]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "matched-pizza",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "matched-pizza",
        "outputId": "29d48ab8-4ff0-4c5c-9409-056158006a9f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "56298"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# 4) \n",
        "# How many tokens are there in the BBC corpus after filter out the stopwords\n",
        "# are these reasonable or to many or too few?\n",
        "words_without_stopwords = remove_stopwords(tokens)\n",
        "len(words_without_stopwords)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "continuing-exposure",
      "metadata": {
        "id": "continuing-exposure"
      },
      "outputs": [],
      "source": [
        "# Check if all stopwords really were removed from the BBC corpus\n",
        "# Can you write a Python function that also matches initial uppercase stopwords\n",
        "def remove_stopwords_case_incensitive(corpus: list):\n",
        "    return [x for x in corpus if x.lower() not in stop_words]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "conscious-apollo",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "conscious-apollo",
        "outputId": "a7892ca7-232f-431f-e7dd-f75984bb7573"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "54005"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# 5)\n",
        "# How many tokens are there in the BBC corpus after filtering also\n",
        "# in lower case?\n",
        "words_without_stopwords_all = remove_stopwords_case_incensitive(tokens)\n",
        "len(words_without_stopwords_all)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "square-credit",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "square-credit",
        "outputId": "4168d971-5753-4094-cac6-9df6d2d6f416"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique tokens with case is  9645 \n",
            "Unique tokens without case is  9565\n"
          ]
        }
      ],
      "source": [
        "# 6)\n",
        "# How many types do you have now?\n",
        "unique_tokens_with_case = set(words_without_stopwords)\n",
        "unique_tokens_without_case = set(words_without_stopwords_all)\n",
        "print(\"Unique tokens with case is \", len(unique_tokens_with_case), \"\\nUnique tokens without case is \", len(unique_tokens_without_case))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "sonic-passage",
      "metadata": {
        "id": "sonic-passage"
      },
      "outputs": [],
      "source": [
        "# Import the WordNet lemmatizer in NLTK\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "mobile-carry",
      "metadata": {
        "id": "mobile-carry"
      },
      "outputs": [],
      "source": [
        "# Write a Python function that lemmatizes the tokens in the BBC corpus\n",
        "def lematize(corpus: list):\n",
        "    lematized_set = set() \n",
        "    for tkn in corpus:\n",
        "        lematized_set.add(lemmatizer.lemmatize(tkn))\n",
        "\n",
        "    return lematized_set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "selective-programming",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "selective-programming",
        "outputId": "07e906d9-baa2-4bbb-fae8-4d01ee61ec23"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9010"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "# 7)\n",
        "# How many types do you have in the BBC corpus after lemmatization?\n",
        "lematized_tokens = lematize(tokens)\n",
        "len(lematized_tokens)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "aquatic-lafayette",
      "metadata": {
        "id": "aquatic-lafayette"
      },
      "outputs": [],
      "source": [
        "#from nltk.stem import PorterStemmer\n",
        "#stemmer =  PorterStemmer()\n",
        "\n",
        "stemmer = nltk.stem.PorterStemmer()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "republican-stranger",
      "metadata": {
        "id": "republican-stranger"
      },
      "outputs": [],
      "source": [
        "# Write a Python function that stems the tokens in the BBC corpus\n",
        "stemmedCorpus = []\n",
        "for w in tokens:\n",
        "    stemmedCorpus.append(stemmer.stem(w))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "specialized-greece",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "specialized-greece",
        "outputId": "5ea94372-3247-4f8c-fe37-f009f02adf2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lemmatized corpus 84335\n",
            "Unique tokens in lemmatized tokens 6643\n"
          ]
        }
      ],
      "source": [
        "# 8)\n",
        "# How many types do you have in the BBC Corpus after stemming?\n",
        "# Are there any differences? If so, why?\n",
        "\n",
        "print(\"Lemmatized corpus\", len(stemmedCorpus))\n",
        "print(\"Unique tokens in lemmatized tokens\", len(set(stemmedCorpus)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "revised-spokesman",
      "metadata": {
        "id": "revised-spokesman"
      },
      "source": [
        "### Now we are ready with the corpus linguistic part of the laboration exercise and we start with POS taggning and Chunking which is more NLP processing tasks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "confused-document",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "confused-document",
        "outputId": "f30a2d78-d4e6-4305-da2f-b068ae1c7a53"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Prime', 'NNP'),\n",
              " ('Minister', 'NNP'),\n",
              " ('Tony', 'NNP'),\n",
              " ('Blair', 'NNP'),\n",
              " ('also', 'RB'),\n",
              " ('expected', 'VBD'),\n",
              " ('announce', 'RB'),\n",
              " ('new', 'JJ'),\n",
              " ('measures', 'NNS'),\n",
              " ('strengthen', 'VBP'),\n",
              " ('use', 'NN'),\n",
              " ('Asbos', 'NNP'),\n",
              " ('fixed', 'VBD'),\n",
              " ('penalty', 'NN'),\n",
              " ('notices', 'NNS'),\n",
              " ('.', '.'),\n",
              " ('still', 'RB'),\n",
              " ('concerns', 'VBZ'),\n",
              " ('areas', 'NNS'),\n",
              " ('country', 'NN'),\n",
              " ('using', 'VBG'),\n",
              " ('powers', 'NNS'),\n",
              " ('properly', 'RB'),\n",
              " ('.', '.'),\n",
              " ('expected', 'VBN'),\n",
              " ('say', 'VBP'),\n",
              " ('new', 'JJ'),\n",
              " ('figures', 'NNS'),\n",
              " ('heartening', 'VBG'),\n",
              " ('would', 'MD'),\n",
              " ('rest', 'VB'),\n",
              " ('similar', 'JJ'),\n",
              " ('action', 'NN'),\n",
              " ('taken', 'VBN'),\n",
              " ('areas', 'NNS'),\n",
              " ('country', 'NN'),\n",
              " ('needed', 'VBD'),\n",
              " ('.', '.'),\n",
              " ('``', '``'),\n",
              " ('defeated', 'VBD'),\n",
              " ('problem', 'NN'),\n",
              " ('means', 'NNS'),\n",
              " (',', ','),\n",
              " ('shown', 'VBN'),\n",
              " ('together', 'RB'),\n",
              " ('done', 'VBN'),\n",
              " (',', ','),\n",
              " (\"''\", \"''\"),\n",
              " ('say', 'VBP'),\n",
              " ('.', '.'),\n",
              " ('Mr', 'NNP'),\n",
              " ('Blair', 'NNP'),\n",
              " ('week', 'NN'),\n",
              " ('defended', 'VBD'),\n",
              " ('shake-up', 'JJ'),\n",
              " ('licensing', 'NN'),\n",
              " ('laws', 'NNS'),\n",
              " (',', ','),\n",
              " ('saying', 'VBG'),\n",
              " ('right', 'JJ'),\n",
              " ('focus', 'NN'),\n",
              " ('troublemakers', 'NNS'),\n",
              " ('rather', 'RB'),\n",
              " ('treating', 'VBG'),\n",
              " ('everybody', 'NN'),\n",
              " ('potential', 'JJ'),\n",
              " ('drunken', 'JJ'),\n",
              " ('nuisance', 'NN'),\n",
              " ('.', '.'),\n",
              " ('Ministers', 'NNS'),\n",
              " ('also', 'RB'),\n",
              " ('boast', 'VBP'),\n",
              " ('record', 'JJ'),\n",
              " ('police', 'NN'),\n",
              " ('numbers', 'NNS'),\n",
              " ('speeding', 'VBG'),\n",
              " ('plans', 'NNS'),\n",
              " ('put', 'VBD'),\n",
              " ('place', 'NN'),\n",
              " ('25,000', 'CD'),\n",
              " ('community', 'NN'),\n",
              " ('support', 'NN'),\n",
              " ('officers', 'NNS'),\n",
              " ('(', '('),\n",
              " ('CSOs', 'NNP'),\n",
              " (')', ')'),\n",
              " ('.', '.'),\n",
              " ('researchers', 'NNS'),\n",
              " ('Leeds', 'NNP'),\n",
              " ('University', 'NNP'),\n",
              " ('warned', 'VBD'),\n",
              " ('CSOs', 'NNP'),\n",
              " ('could', 'MD'),\n",
              " ('undermine', 'VB'),\n",
              " ('traditional', 'JJ'),\n",
              " ('bonds', 'NNS'),\n",
              " ('police', 'JJ'),\n",
              " ('officers', 'NNS'),\n",
              " ('communities', 'NNS'),\n",
              " ('.', '.'),\n",
              " ('work', 'NN'),\n",
              " ('needed', 'VBD'),\n",
              " ('done', 'VBN'),\n",
              " ('clarifying', 'VBG'),\n",
              " ('role', 'NN'),\n",
              " ('different', 'JJ'),\n",
              " ('agencies', 'NNS'),\n",
              " ('linked', 'VBN'),\n",
              " ('together', 'RB'),\n",
              " ('CSOs', 'NNP'),\n",
              " (',', ','),\n",
              " ('argued', 'VBD'),\n",
              " ('study', 'NN'),\n",
              " ('.', '.'),\n",
              " ('Critics', 'JJ'),\n",
              " ('government', 'NN'),\n",
              " ('say', 'VBP'),\n",
              " ('announced', 'VBD'),\n",
              " ('20', 'CD'),\n",
              " ('initiatives', 'NNS'),\n",
              " ('tackle', 'JJ'),\n",
              " ('nuisance', 'RB'),\n",
              " ('behaviour', 'JJ'),\n",
              " ('real', 'JJ'),\n",
              " ('focus', 'NN'),\n",
              " ('good', 'JJ'),\n",
              " ('policing', 'NN'),\n",
              " ('.', '.'),\n",
              " ('Home', 'NNP'),\n",
              " ('Office', 'NNP'),\n",
              " ('Minister', 'NNP'),\n",
              " ('Hazel', 'NNP'),\n",
              " ('Blears', 'NNP'),\n",
              " ('also', 'RB'),\n",
              " ('revealed', 'VBD'),\n",
              " ('week', 'NN'),\n",
              " ('``', '``'),\n",
              " ('third', 'JJ'),\n",
              " (\"''\", \"''\"),\n",
              " ('Asbos', 'NNP'),\n",
              " ('breached', 'VBD'),\n",
              " ('-', ':'),\n",
              " ('people', 'NNS'),\n",
              " ('jailed', 'JJ'),\n",
              " ('others', 'NNS'),\n",
              " ('.', '.'),\n",
              " ('Kennedy', 'NNP'),\n",
              " ('calls', 'VBZ'),\n",
              " ('Iraq', 'NNP'),\n",
              " ('exit', 'NN'),\n",
              " ('plans', 'NNS'),\n",
              " ('Tony', 'NNP'),\n",
              " ('Blair', 'NNP'),\n",
              " ('set', 'VBD'),\n",
              " ('proper', 'JJ'),\n",
              " ('exit', 'NN'),\n",
              " ('strategy', 'NN'),\n",
              " ('Iraq', 'NNP'),\n",
              " ('wake', 'NN'),\n",
              " ('next', 'JJ'),\n",
              " ('Sunday', 'NNP'),\n",
              " (\"'s\", 'POS'),\n",
              " ('elections', 'NNS'),\n",
              " ('country', 'NN'),\n",
              " (',', ','),\n",
              " ('Lib', 'NNP'),\n",
              " ('Dem', 'NNP'),\n",
              " ('leader', 'NN'),\n",
              " ('Charles', 'NNP'),\n",
              " ('Kennedy', 'NNP'),\n",
              " ('said', 'VBD'),\n",
              " ('.', '.'),\n",
              " ('speech', 'NN'),\n",
              " ('focusing', 'VBG'),\n",
              " ('issues', 'NNS'),\n",
              " ('arising', 'VBG'),\n",
              " ('re-election', 'NN'),\n",
              " ('George', 'NNP'),\n",
              " ('W', 'NNP'),\n",
              " ('Bush', 'NNP'),\n",
              " (',', ','),\n",
              " ('Mr', 'NNP'),\n",
              " ('Kennedy', 'NNP'),\n",
              " ('said', 'VBD'),\n",
              " ('Iraq', 'NNP'),\n",
              " ('become', 'VB'),\n",
              " ('``', '``'),\n",
              " ('crucible', 'JJ'),\n",
              " ('militant', 'JJ'),\n",
              " ('terrorism', 'NN'),\n",
              " (\"''\", \"''\"),\n",
              " ('.', '.'),\n",
              " ('wants', 'VBZ'),\n",
              " ('see', 'VBP'),\n",
              " ('phased', 'JJ'),\n",
              " ('withdrawal', 'NN'),\n",
              " ('UK', 'NNP'),\n",
              " ('troops', 'VBZ'),\n",
              " ('``', '``'),\n",
              " ('soon', 'RB'),\n",
              " ('situation', 'NN'),\n",
              " ('allows', 'NNS'),\n",
              " (\"''\", \"''\"),\n",
              " (',', ','),\n",
              " ('said', 'VBD'),\n",
              " ('London', 'NNP'),\n",
              " ('.', '.'),\n",
              " ('exit', 'NN'),\n",
              " ('strategy', 'NN'),\n",
              " ('must', 'MD'),\n",
              " ('``', '``'),\n",
              " ('augment', 'VB'),\n",
              " ('support', 'NN'),\n",
              " (\"''\", \"''\"),\n",
              " ('democratic', 'JJ'),\n",
              " ('process', 'NN'),\n",
              " ('.', '.'),\n",
              " ('``', '``'),\n",
              " ('opinion', 'NN'),\n",
              " ('mere', 'JJ'),\n",
              " ('presence', 'NN'),\n",
              " ('British', 'JJ'),\n",
              " ('American', 'JJ'),\n",
              " ('troops', 'NNS'),\n",
              " ('Iraq', 'NNP'),\n",
              " ('feeds', 'NNS'),\n",
              " ('insurgency', 'NN'),\n",
              " (',', ','),\n",
              " (\"''\", \"''\"),\n",
              " ('said', 'VBD'),\n",
              " ('.', '.'),\n",
              " ('``', '``'),\n",
              " ('truth', 'NN'),\n",
              " (',', ','),\n",
              " ('especially', 'RB'),\n",
              " ('initial', 'JJ'),\n",
              " ('mistakes', 'NNS'),\n",
              " ('made', 'VBN'),\n",
              " ('-', ':'),\n",
              " ('heavy-handedness', 'JJ'),\n",
              " ('operations', 'NNS'),\n",
              " ('like', 'IN'),\n",
              " ('Fallujah', 'NNP'),\n",
              " (',', ','),\n",
              " ('well-publicised', 'JJ'),\n",
              " ('instances', 'NNS'),\n",
              " ('abuse', 'IN'),\n",
              " ('hands', 'NNS'),\n",
              " ('coalition', 'NN'),\n",
              " ('forces', 'NNS'),\n",
              " ('.', '.'),\n",
              " (\"''\", \"''\"),\n",
              " ('Mr', 'NNP'),\n",
              " ('Kennedy', 'NNP'),\n",
              " ('pointed', 'VBD'),\n",
              " ('Netherlands', 'NNP'),\n",
              " (',', ','),\n",
              " ('Portugal', 'NNP'),\n",
              " ('Czech', 'NNP'),\n",
              " ('Republic', 'NNP'),\n",
              " (',', ','),\n",
              " ('troops', 'VBZ'),\n",
              " ('operating', 'VBG'),\n",
              " ('southern', 'JJ'),\n",
              " ('sector', 'NN'),\n",
              " ('Iraq', 'NNP'),\n",
              " (',', ','),\n",
              " ('announced', 'VBD'),\n",
              " ('imminent', 'JJ'),\n",
              " ('withdrawal', 'NN'),\n",
              " ('``', '``'),\n",
              " ('regardless', 'JJ'),\n",
              " ('situation', 'NN'),\n",
              " ('ground', 'NN'),\n",
              " (\"''\", \"''\"),\n",
              " ('.', '.'),\n",
              " ('accused', 'VBN'),\n",
              " ('Mr', 'NNP'),\n",
              " ('Blair', 'NNP'),\n",
              " (\"'s\", 'POS'),\n",
              " ('government', 'NN'),\n",
              " ('``', '``'),\n",
              " ('less', 'JJR'),\n",
              " ('straightforward', 'NN'),\n",
              " (\"''\", \"''\"),\n",
              " ('plans', 'NNS'),\n",
              " ('.', '.'),\n",
              " ('``', '``'),\n",
              " ('Next', 'JJ'),\n",
              " ('week', 'NN'),\n",
              " ('prime', 'JJ'),\n",
              " ('minister', 'NN'),\n",
              " ('make', 'VBP'),\n",
              " ('statement', 'NN'),\n",
              " ('regarding', 'VBG'),\n",
              " ('elections', 'NNS'),\n",
              " ('Iraq', 'NNP'),\n",
              " (',', ','),\n",
              " (\"''\", \"''\"),\n",
              " ('Mr', 'NNP'),\n",
              " ('Kennedy', 'NNP'),\n",
              " ('said', 'VBD'),\n",
              " ('City', 'NNP'),\n",
              " ('London', 'NNP'),\n",
              " ('speech', 'NN'),\n",
              " ('.', '.'),\n",
              " ('``', '``'),\n",
              " ('set', 'VBN'),\n",
              " ('proper', 'JJ'),\n",
              " ('exit', 'NN'),\n",
              " ('strategy', 'NN'),\n",
              " (',', ','),\n",
              " ('including', 'VBG'),\n",
              " ('phased', 'VBD'),\n",
              " ('withdrawal', 'NN'),\n",
              " ('British', 'JJ'),\n",
              " ('troops', 'NNS'),\n",
              " (',', ','),\n",
              " ('security', 'NN'),\n",
              " ('situation', 'NN'),\n",
              " ('allows', 'VBZ'),\n",
              " ('.', '.'),\n",
              " (\"''\", \"''\"),\n",
              " ('Mr', 'NNP'),\n",
              " ('Kennedy', 'NNP'),\n",
              " ('also', 'RB'),\n",
              " ('argued', 'VBD'),\n",
              " ('British', 'JJ'),\n",
              " ('troops', 'NNS'),\n",
              " ('deployed', 'VBD'),\n",
              " ('Iraq', 'NNP'),\n",
              " ('replaced', 'VBD'),\n",
              " ('forces', 'NNS'),\n",
              " ('countries', 'NNS'),\n",
              " ('-', ':'),\n",
              " ('``', '``'),\n",
              " ('especially', 'RB'),\n",
              " ('Islamic', 'JJ'),\n",
              " ('countries', 'NNS'),\n",
              " (\"''\", \"''\"),\n",
              " ('.', '.'),\n",
              " ('McConnell', 'NNP'),\n",
              " (\"'drunk\", 'NNP'),\n",
              " (\"'\", 'POS'),\n",
              " ('remark', 'NN'),\n",
              " ('row', 'NN'),\n",
              " ('Scotland', 'NNP'),\n",
              " (\"'s\", 'POS'),\n",
              " ('first', 'JJ'),\n",
              " ('minister', 'NN'),\n",
              " ('told', 'VBD'),\n",
              " ('group', 'NN'),\n",
              " ('high', 'JJ'),\n",
              " ('school', 'NN'),\n",
              " ('pupils', 'NNS'),\n",
              " ('okay', 'VBP'),\n",
              " ('get', 'VB'),\n",
              " ('drunk', 'JJ'),\n",
              " ('``', '``'),\n",
              " (\"''\", \"''\"),\n",
              " ('.', '.'),\n",
              " ('Jack', 'NNP'),\n",
              " ('McConnell', 'NNP'),\n",
              " ('speaking', 'VBG'),\n",
              " ('100', 'CD'),\n",
              " ('secondary', 'JJ'),\n",
              " ('pupils', 'NNS'),\n",
              " ('schools', 'NNS'),\n",
              " ('Highlands', 'NNP'),\n",
              " ('problems', 'NNS'),\n",
              " ('binge', 'VBP'),\n",
              " ('drinking', 'VBG'),\n",
              " ('drink', 'NN'),\n",
              " ('promotions', 'NNS'),\n",
              " ('.', '.'),\n",
              " ('criticised', 'VBN'),\n",
              " ('SNP', 'NNP'),\n",
              " ('encouraging', 'JJ'),\n",
              " ('young', 'JJ'),\n",
              " ('people', 'NNS'),\n",
              " ('get', 'VBP'),\n",
              " ('drunk', 'JJ'),\n",
              " ('.', '.'),\n",
              " ('Scottish', 'JJ'),\n",
              " ('Executive', 'NNP'),\n",
              " ('insisted', 'VBD'),\n",
              " ('Mr', 'NNP'),\n",
              " ('McConnell', 'NNP'),\n",
              " ('speaking', 'VBG'),\n",
              " ('adults', 'NNS'),\n",
              " ('comments', 'NNS'),\n",
              " ('``', '``'),\n",
              " ('recognition', 'NN'),\n",
              " ('people', 'NNS'),\n",
              " ('get', 'VBP'),\n",
              " ('drunk', 'JJ'),\n",
              " (\"''\", \"''\"),\n",
              " ('.', '.'),\n",
              " ('first', 'JJ'),\n",
              " ('minister', 'NN'),\n",
              " (\"'s\", 'POS'),\n",
              " ('comments', 'NNS'),\n",
              " ('came', 'VBD'),\n",
              " ('question', 'NN'),\n",
              " ('answer', 'NN'),\n",
              " ('session', 'NN'),\n",
              " ('Glenurquhart', 'NNP'),\n",
              " ('High', 'NNP'),\n",
              " ('School', 'NNP'),\n",
              " ('Inverness', 'NNP'),\n",
              " (',', ','),\n",
              " ('attended', 'VBD'),\n",
              " ('pupils', 'NNS'),\n",
              " ('number', 'NN'),\n",
              " ('secondary', 'JJ'),\n",
              " ('schools', 'NNS'),\n",
              " ('.', '.'),\n",
              " ('Highland', 'NNP'),\n",
              " ('councillor', 'NN'),\n",
              " ('event', 'NN'),\n",
              " ('also', 'RB'),\n",
              " ('defended', 'VBD'),\n",
              " ('Mr', 'NNP'),\n",
              " ('McConnell', 'NNP'),\n",
              " ('.', '.'),\n",
              " ('Margaret', 'NNP'),\n",
              " ('Davidson', 'NNP'),\n",
              " (',', ','),\n",
              " ('independent', 'JJ'),\n",
              " ('member', 'NN'),\n",
              " ('Loch', 'NNP'),\n",
              " ('Ness', 'NNP'),\n",
              " ('West', 'NNP'),\n",
              " (',', ','),\n",
              " ('said', 'VBD'),\n",
              " ('first', 'JJ'),\n",
              " ('minister', 'NN'),\n",
              " ('speaking', 'VBG'),\n",
              " ('general', 'JJ'),\n",
              " ('way', 'NN'),\n",
              " ('sure', 'JJ'),\n",
              " ('speaking', 'VBG'),\n",
              " ('adults', 'JJ'),\n",
              " ('time', 'NN'),\n",
              " ('.', '.'),\n",
              " ('one', 'CD'),\n",
              " ('pupil', 'NN'),\n",
              " ('asked', 'VBD'),\n",
              " ('Mr', 'NNP'),\n",
              " ('McConnell', 'NNP'),\n",
              " ('executive', 'NN'),\n",
              " ('proposed', 'VBD'),\n",
              " ('tackle', 'JJ'),\n",
              " ('under-age', 'JJ'),\n",
              " ('drinking', 'NN'),\n",
              " (',', ','),\n",
              " ('began', 'VBD'),\n",
              " ('response', 'NN'),\n",
              " ('quip', 'NN'),\n",
              " (':', ':'),\n",
              " ('``', '``'),\n",
              " (\"'m\", 'VBP'),\n",
              " ('sure', 'JJ'),\n",
              " (\"'s\", 'POS'),\n",
              " ('under-age', 'JJ'),\n",
              " ('drinking', 'NN'),\n",
              " ('Highlands', 'NNP'),\n",
              " ('.', '.'),\n",
              " (\"''\", \"''\"),\n",
              " ('went', 'VBD'),\n",
              " ('speak', 'NN'),\n",
              " ('evils', 'NNS'),\n",
              " ('binge', 'VBP'),\n",
              " ('drinking', 'VBG'),\n",
              " ('railed', 'VBD'),\n",
              " ('irresponsible', 'JJ'),\n",
              " ('drinks', 'NNS'),\n",
              " ('promotions', 'NNS'),\n",
              " ('.', '.'),\n",
              " ('said', 'VBD'),\n",
              " (':', ':'),\n",
              " ('``', '``'),\n",
              " ('hope', 'NN'),\n",
              " (\"'m\", 'VBP'),\n",
              " ('going', 'VBG'),\n",
              " ('seen', 'VBN'),\n",
              " ('preaching', 'VBG'),\n",
              " ('anybody', 'NN'),\n",
              " ('really', 'RB'),\n",
              " ('serious', 'JJ'),\n",
              " ('problem', 'NN'),\n",
              " ('moment', 'NN'),\n",
              " ('binge', 'NN'),\n",
              " ('drinking', 'VBG'),\n",
              " ('impact', 'JJ'),\n",
              " ('people', 'NNS'),\n",
              " (\"'s\", 'POS'),\n",
              " ('health', 'NN'),\n",
              " ('ability', 'NN'),\n",
              " ('control', 'NN'),\n",
              " (\"'s\", 'POS'),\n",
              " ('happening', 'VBG'),\n",
              " ('round', 'NN'),\n",
              " ('.', '.'),\n",
              " (\"''\", \"''\"),\n",
              " ('Mr', 'NNP'),\n",
              " ('McConnell', 'NNP'),\n",
              " ('said', 'VBD'),\n",
              " ('regularly', 'RB'),\n",
              " ('saw', 'JJ'),\n",
              " ('reports', 'NNS'),\n",
              " ('effects', 'NNS'),\n",
              " ('binge', 'VBP'),\n",
              " ('drinking', 'VBG'),\n",
              " ('sprees', 'NNS'),\n",
              " ('ended', 'VBD'),\n",
              " ('assaults', 'RB'),\n",
              " ('even', 'RB'),\n",
              " ('rapes', 'NNS'),\n",
              " (',', ','),\n",
              " ('health', 'NN'),\n",
              " ('consequences', 'NNS'),\n",
              " ('binge', 'VBP'),\n",
              " ('drinking', 'NN'),\n",
              " ('.', '.'),\n",
              " ('``', '``'),\n",
              " ('one', 'CD'),\n",
              " ('thing', 'NN'),\n",
              " ('going', 'VBG'),\n",
              " ('something', 'NN'),\n",
              " ('really', 'RB'),\n",
              " ('serious', 'JJ'),\n",
              " ('binge', 'NN'),\n",
              " ('drinking', 'VBG'),\n",
              " ('irresponsible', 'JJ'),\n",
              " ('drinks', 'NNS'),\n",
              " ('promotions', 'NNS'),\n",
              " ('help', 'VBP'),\n",
              " ('lead', 'VB'),\n",
              " (',', ','),\n",
              " (\"''\", \"''\"),\n",
              " ('said', 'VBD'),\n",
              " ('.', '.'),\n",
              " ('``', '``'),\n",
              " ('Far', 'NNP'),\n",
              " ('many', 'JJ'),\n",
              " ('pub', 'NN'),\n",
              " ('chains', 'NNS'),\n",
              " ('particular', 'JJ'),\n",
              " ('selling', 'VBG'),\n",
              " ('far', 'RB'),\n",
              " ('much', 'JJ'),\n",
              " ('booze', 'NN'),\n",
              " ('far', 'RB'),\n",
              " ('cheaply', 'RB'),\n",
              " ('encouraging', 'JJ'),\n",
              " ('people', 'NNS'),\n",
              " ('drink', 'VBP'),\n",
              " ('far', 'RB'),\n",
              " ('quickly', 'RB'),\n",
              " ('.', '.'),\n",
              " ('``', '``'),\n",
              " ('go', 'VBP'),\n",
              " ('clamp', 'JJ'),\n",
              " ('make', 'VBP'),\n",
              " ('promotions', 'NNS'),\n",
              " ('illegal', 'JJ'),\n",
              " ('hope', 'VBP'),\n",
              " ('people', 'NNS'),\n",
              " ('enjoy', 'VBP'),\n",
              " ('drink', 'VB'),\n",
              " ('sensibly', 'RB'),\n",
              " ('course', 'NN'),\n",
              " ('evening', 'NN'),\n",
              " ('.', '.'),\n",
              " (\"''\", \"''\"),\n",
              " ('added', 'VBD'),\n",
              " (':', ':'),\n",
              " ('``', '``'),\n",
              " ('means', 'VBZ'),\n",
              " ('get', 'VBP'),\n",
              " ('drunk', 'VBN'),\n",
              " ('-', ':'),\n",
              " ('get', 'VB'),\n",
              " ('situation', 'NN'),\n",
              " ('people', 'NNS'),\n",
              " ('encouraged', 'VBD'),\n",
              " ('get', 'VB'),\n",
              " ('completely', 'RB'),\n",
              " ('incapable', 'JJ'),\n",
              " ('save', 'VB'),\n",
              " ('money', 'NN'),\n",
              " ('drink', 'NN'),\n",
              " ('quickly', 'RB'),\n",
              " ('.', '.'),\n",
              " (\"''\", \"''\"),\n",
              " ('SNP', 'NNP'),\n",
              " ('Holyrood', 'NNP'),\n",
              " ('leader', 'NN'),\n",
              " ('Nicola', 'NNP'),\n",
              " ('Sturgeon', 'NNP'),\n",
              " ('said', 'VBD'),\n",
              " (':', ':'),\n",
              " ('``', '``'),\n",
              " ('incredible', 'JJ'),\n",
              " ('gaffe', 'NN'),\n",
              " ('Jack', 'NNP'),\n",
              " ('McConnell', 'NNP'),\n",
              " ('.', '.'),\n",
              " ('``', '``'),\n",
              " ('know', 'JJ'),\n",
              " ('under-age', 'JJ'),\n",
              " ('drinking', 'NN'),\n",
              " ('issue', 'NN'),\n",
              " ('Scotland', 'NNP'),\n",
              " ('quite', 'RB'),\n",
              " ('staggering', 'VBG'),\n",
              " ('politician', 'JJ'),\n",
              " (',', ','),\n",
              " ('particularly', 'RB'),\n",
              " ('First', 'JJ'),\n",
              " ('Minister', 'NNP'),\n",
              " (',', ','),\n",
              " ('encourage', 'VB'),\n",
              " ('young', 'JJ'),\n",
              " ('people', 'NNS'),\n",
              " ('get', 'VBP'),\n",
              " ('drunk', 'JJ'),\n",
              " ('.', '.'),\n",
              " ('``', '``'),\n",
              " ('first', 'JJ'),\n",
              " ('minister', 'NN'),\n",
              " ('withdraw', 'NN'),\n",
              " ('remarks', 'NNS'),\n",
              " ('immediately', 'RB'),\n",
              " ('.', '.'),\n",
              " (\"''\", \"''\"),\n",
              " ('executive', 'NN'),\n",
              " ('spokeswoman', 'NN'),\n",
              " ('insisted', 'VBD'),\n",
              " ('Mr', 'NNP'),\n",
              " ('McConnell', 'NNP'),\n",
              " ('made', 'VBD'),\n",
              " ('remark', 'NN'),\n",
              " ('adults', 'NNS'),\n",
              " (',', ','),\n",
              " ('youngsters', 'NNS'),\n",
              " (',', ','),\n",
              " ('mind', 'NN'),\n",
              " ('.', '.'),\n",
              " ('``', '``'),\n",
              " ('talking', 'VBG'),\n",
              " ('context', 'JJ'),\n",
              " ('adults', 'NNS'),\n",
              " ('binge', 'VBP'),\n",
              " ('drinking', 'VBG'),\n",
              " ('irresponsible', 'JJ'),\n",
              " ('drinks', 'NNS'),\n",
              " ('promotions', 'NNS'),\n",
              " ('-', ':'),\n",
              " ('over-18s', 'NN'),\n",
              " (',', ','),\n",
              " (\"''\", \"''\"),\n",
              " ('said', 'VBD'),\n",
              " ('.', '.'),\n",
              " ('``', '``'),\n",
              " ('recognition', 'NN'),\n",
              " ('people', 'NNS'),\n",
              " ('get', 'VBP'),\n",
              " ('drunk', 'JJ'),\n",
              " (',', ','),\n",
              " ('binge', 'JJ'),\n",
              " ('drinking', 'VBG'),\n",
              " ('drinks', 'NNS'),\n",
              " ('promotions', 'NNS'),\n",
              " ('encourage', 'VBP'),\n",
              " ('acceptable', 'JJ'),\n",
              " ('.', '.'),\n",
              " (\"''\", \"''\"),\n",
              " ('Brown', 'NNP'),\n",
              " ('hits', 'VBZ'),\n",
              " ('back', 'RB'),\n",
              " ('Blair', 'NNP'),\n",
              " ('rift', 'NN'),\n",
              " ('row', 'NN'),\n",
              " ('Gordon', 'NNP'),\n",
              " ('Brown', 'NNP'),\n",
              " ('criticised', 'VBD'),\n",
              " ('union', 'NN'),\n",
              " ('leader', 'NN'),\n",
              " ('said', 'VBD'),\n",
              " ('conflict', 'NN'),\n",
              " ('Tony', 'NNP'),\n",
              " ('Blair', 'NNP'),\n",
              " ('harming', 'VBG'),\n",
              " ('workings', 'JJ'),\n",
              " ('government', 'NN'),\n",
              " ('.', '.'),\n",
              " ('Jonathan', 'NNP'),\n",
              " ('Baume', 'NNP'),\n",
              " (',', ','),\n",
              " ('top', 'JJ'),\n",
              " ('civil', 'JJ'),\n",
              " ('servants', 'NNS'),\n",
              " (\"'\", 'POS'),\n",
              " ('union', 'NN'),\n",
              " (',', ','),\n",
              " ('spoke', 'VBD'),\n",
              " ('``', '``'),\n",
              " ('competing', 'VBG'),\n",
              " ('agendas', 'NNS'),\n",
              " (\"''\", \"''\"),\n",
              " ('Mr', 'NNP'),\n",
              " ('Brown', 'NNP'),\n",
              " ('Mr', 'NNP'),\n",
              " ('Blair', 'NNP'),\n",
              " ('.', '.'),\n",
              " ('chancellor', 'NN'),\n",
              " ('said', 'VBD'),\n",
              " ('Mr', 'NNP'),\n",
              " ('Baume', 'NNP'),\n",
              " ('never', 'RB'),\n",
              " ('meetings', 'NNS'),\n",
              " ('prime', 'JJ'),\n",
              " ('minister', 'NN'),\n",
              " ('could', 'MD'),\n",
              " ('judge', 'VB'),\n",
              " ('.', '.'),\n",
              " ('said', 'VBD'),\n",
              " ('union', 'NN'),\n",
              " ('leader', 'NN'),\n",
              " ('trying', 'VBG'),\n",
              " ('block', 'NNP'),\n",
              " ('civil', 'JJ'),\n",
              " ('service', 'NN'),\n",
              " ('reform', 'NN'),\n",
              " ('threatened', 'VBD'),\n",
              " ('members', 'NNS'),\n",
              " (\"'\", 'POS'),\n",
              " ('jobs', 'NNS'),\n",
              " ('.', '.'),\n",
              " ('suited', 'VBN'),\n",
              " ('purpose', 'JJ'),\n",
              " ('Mr', 'NNP'),\n",
              " ('Baume', 'NNP'),\n",
              " (\"'s\", 'POS'),\n",
              " ('union', 'NN'),\n",
              " (',', ','),\n",
              " ('First', 'NNP'),\n",
              " ('Division', 'NNP'),\n",
              " ('Association', 'NNP'),\n",
              " (',', ','),\n",
              " ('suggest', 'VBP'),\n",
              " ('two', 'CD'),\n",
              " ('agendas', 'NNS'),\n",
              " ('battling', 'VBG'),\n",
              " ('union', 'NN'),\n",
              " ('trying', 'VBG'),\n",
              " ('resist', 'NN'),\n",
              " ('planned', 'VBD'),\n",
              " ('reforms', 'NNS'),\n",
              " (',', ','),\n",
              " ('Mr', 'NNP'),\n",
              " ('Brown', 'NNP'),\n",
              " ('told', 'VBD'),\n",
              " ('BBC', 'NNP'),\n",
              " ('Radio', 'NNP'),\n",
              " ('4', 'CD'),\n",
              " (\"'s\", 'POS'),\n",
              " ('Today', 'NN'),\n",
              " ('programme', 'NN'),\n",
              " ('.', '.'),\n",
              " ('plans', 'NNS'),\n",
              " (',', ','),\n",
              " ('unveiled', 'VBD'),\n",
              " ('Gershon', 'NNP'),\n",
              " ('report', 'NN'),\n",
              " (',', ','),\n",
              " ('84,000', 'CD'),\n",
              " ('civil', 'JJ'),\n",
              " ('servants', 'NNS'),\n",
              " ('jobs', 'NNS'),\n",
              " ('axed', 'RB'),\n",
              " ('changed', 'VBD'),\n",
              " ('savings', 'NNS'),\n",
              " ('ploughed', 'VBN'),\n",
              " ('back', 'RB'),\n",
              " ('frontline', 'JJ'),\n",
              " ('services', 'NNS'),\n",
              " ('.', '.'),\n",
              " ('Mr', 'NNP'),\n",
              " ('Brown', 'NNP'),\n",
              " ('said', 'VBD'),\n",
              " (':', ':'),\n",
              " ('``', '``'),\n",
              " ('honest', 'VBP'),\n",
              " (\"n't\", 'RB'),\n",
              " ('think', 'VB'),\n",
              " ('rely', 'RB'),\n",
              " ('[', 'JJ'),\n",
              " ('Mr', 'NNP'),\n",
              " ('Baume', 'NNP'),\n",
              " (\"'s\", 'POS'),\n",
              " (']', 'JJ'),\n",
              " ('judgement', 'NN'),\n",
              " ('matter', 'NN'),\n",
              " ('comes', 'VBZ'),\n",
              " ('decisions', 'NNS'),\n",
              " ('government', 'NN'),\n",
              " ('making', 'NN'),\n",
              " ('.', '.'),\n",
              " ('``', '``'),\n",
              " ('Mr', 'NNP'),\n",
              " ('Blair', 'NNP'),\n",
              " ('making', 'VBG'),\n",
              " ('exactly', 'RB'),\n",
              " ('decisions', 'NNS'),\n",
              " ('civil', 'JJ'),\n",
              " ('service', 'NN'),\n",
              " ('reforms', 'NNS'),\n",
              " ('.', '.'),\n",
              " ('determined', 'VBD'),\n",
              " ('go', 'VB'),\n",
              " ('Gershon', 'NNP'),\n",
              " ('reforms', 'NNS'),\n",
              " ('.', '.'),\n",
              " (\"''\", \"''\"),\n",
              " ('also', 'RB'),\n",
              " ('said', 'VBD'),\n",
              " ('Mr', 'NNP'),\n",
              " ('Baume', 'NNP'),\n",
              " ('never', 'RB'),\n",
              " ('present', 'JJ'),\n",
              " ('meetings', 'NNS'),\n",
              " ('prime', 'JJ'),\n",
              " ('minister', 'NN'),\n",
              " (',', ','),\n",
              " ('position', 'NN'),\n",
              " ('judge', 'NN'),\n",
              " ('.', '.'),\n",
              " ('Wednesday', 'NNP'),\n",
              " (',', ','),\n",
              " ('ahead', 'RB'),\n",
              " ('Chancellor', 'NNP'),\n",
              " (\"'s\", 'POS'),\n",
              " ('pre-Budget', 'JJ'),\n",
              " ('report', 'NN'),\n",
              " (',', ','),\n",
              " ('Mr', 'NNP'),\n",
              " ('Baume', 'NNP'),\n",
              " ('told', 'VBD'),\n",
              " ('BBC', 'NNP'),\n",
              " ('News', 'NNP'),\n",
              " ('sometimes', 'RB'),\n",
              " ('``', '``'),\n",
              " ('conflicting', 'VBG'),\n",
              " ('competing', 'VBG'),\n",
              " ('agendas', 'JJ'),\n",
              " ('government', 'NN'),\n",
              " (\"''\", \"''\"),\n",
              " ('Number', 'NNP'),\n",
              " ('10', 'CD'),\n",
              " ('Treasury', 'NNP'),\n",
              " ('.', '.'),\n",
              " ('chancellor', 'NN'),\n",
              " ('wanted', 'VBD'),\n",
              " ('``', '``'),\n",
              " ('means', 'NNS'),\n",
              " ('Alan', 'NNP'),\n",
              " ('Milburn', 'NNP'),\n",
              " ('prime', 'JJ'),\n",
              " ('minister', 'NN'),\n",
              " ('want', 'VBP'),\n",
              " ('see', 'NN'),\n",
              " (\"''\", \"''\"),\n",
              " (',', ','),\n",
              " ('Mr', 'NNP'),\n",
              " ('Baume', 'NNP'),\n",
              " ('said', 'VBD'),\n",
              " ('.', '.'),\n",
              " ('``', '``'),\n",
              " ('Government', 'NNP'),\n",
              " ('departments', 'NNS'),\n",
              " ('get', 'VB'),\n",
              " ('money', 'NN'),\n",
              " ('Treasury', 'NNP'),\n",
              " ('basis', 'NN'),\n",
              " ('public', 'NN'),\n",
              " ('service', 'NN'),\n",
              " ('agreements', 'NNS'),\n",
              " ('sign', 'NN'),\n",
              " (',', ','),\n",
              " ('time', 'NN'),\n",
              " ('prime', 'JJ'),\n",
              " ('minister', 'NN'),\n",
              " ('also', 'RB'),\n",
              " ('agenda', 'VBP'),\n",
              " (\"'s\", 'POS'),\n",
              " ('necessarily', 'JJ'),\n",
              " ('Treasury', 'NNP'),\n",
              " (\"'s\", 'POS'),\n",
              " ('prime', 'JJ'),\n",
              " ('minister', 'NN'),\n",
              " ('course', 'NN'),\n",
              " ('powerful', 'JJ'),\n",
              " ('figure', 'JJ'),\n",
              " ('government', 'NN'),\n",
              " ('.', '.'),\n",
              " ('``', '``'),\n",
              " ('also', 'RB'),\n",
              " ('sends', 'VBZ'),\n",
              " ('instructions', 'NNS'),\n",
              " ('messages', 'NNS'),\n",
              " ('directions', 'NNS'),\n",
              " ('departments', 'NNS'),\n",
              " ('would', 'MD'),\n",
              " ('like', 'VB'),\n",
              " ('secretary', 'NN'),\n",
              " ('state', 'NN'),\n",
              " ('department', 'NN'),\n",
              " ('implement', 'NN'),\n",
              " ('policy', 'NN'),\n",
              " ('agenda', 'NN'),\n",
              " ('.', '.'),\n",
              " ('``', '``'),\n",
              " ('problem', 'NN'),\n",
              " ('many', 'JJ'),\n",
              " ('occasions', 'NNS'),\n",
              " ('two', 'CD'),\n",
              " (\"n't\", 'RB'),\n",
              " ('add', 'VB'),\n",
              " ('individual', 'JJ'),\n",
              " ('cabinet', 'NN'),\n",
              " ('ministers', 'NNS'),\n",
              " ('well', 'VBP'),\n",
              " ('departments', 'NNS'),\n",
              " ('make', 'VBP'),\n",
              " ('sense', 'NN'),\n",
              " ('battle', 'NN'),\n",
              " ('.', '.'),\n",
              " (\"''\", \"''\"),\n",
              " ('Number', 'NNP'),\n",
              " ('10', 'CD'),\n",
              " ('said', 'VBD'),\n",
              " ('ministers', 'NNS'),\n",
              " ('interested', 'JJ'),\n",
              " ('governing', 'VBG'),\n",
              " ('``', '``'),\n",
              " ('soap', 'NN'),\n",
              " ('opera', 'NN'),\n",
              " (\"''\", \"''\"),\n",
              " ('Mr', 'NNP'),\n",
              " ('Blair', 'NNP'),\n",
              " ('Mr', 'NNP'),\n",
              " ('Brown', 'NNP'),\n",
              " ('.', '.'),\n",
              " ('Tory', 'NNP'),\n",
              " ('shadow', 'JJ'),\n",
              " ('chancellor', 'NN'),\n",
              " ('Oliver', 'NNP'),\n",
              " ('Letwin', 'NNP'),\n",
              " ('said', 'VBD'),\n",
              " (':', ':'),\n",
              " ('``', '``'),\n",
              " ('battle', 'NN'),\n",
              " ('Royal', 'NNP'),\n",
              " ('top', 'JJ'),\n",
              " ('civil', 'JJ'),\n",
              " ('servants', 'NNS'),\n",
              " ('reporting', 'VBG'),\n",
              " ('chancellor', 'NN'),\n",
              " ('Tony', 'NNP'),\n",
              " ('Blair', 'NNP'),\n",
              " ('preventing', 'VBG'),\n",
              " ('getting', 'VBG'),\n",
              " ('business', 'NN'),\n",
              " ('getting', 'VBG'),\n",
              " ('taxpayers', 'NNS'),\n",
              " ('value', 'NN'),\n",
              " ('money', 'NN'),\n",
              " ('.', '.'),\n",
              " (\"''\", \"''\"),\n",
              " ('Tories', 'NNPS'),\n",
              " (\"'would\", 'MD'),\n",
              " ('cut', 'VB'),\n",
              " ('number', 'NN'),\n",
              " (\"MPs'\", 'NNP'),\n",
              " ('Conservative', 'NNP'),\n",
              " ('Party', 'NNP'),\n",
              " ('would', 'MD'),\n",
              " ('cut', 'VB'),\n",
              " ('number', 'NN'),\n",
              " ('MPs', 'NNP'),\n",
              " ('one-fifth', 'JJ'),\n",
              " ('elected', 'VBN'),\n",
              " (',', ','),\n",
              " ('Tory', 'NNP'),\n",
              " ('leader', 'NN'),\n",
              " ('Michael', 'NNP'),\n",
              " ('Howard', 'NNP'),\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "# Use the nltk.pos_tag() function to POS tag the BBC corpus\n",
        "tagged_txt = nltk.pos_tag(words_without_stopwords_all)\n",
        "tagged_txt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "444d64da",
      "metadata": {
        "id": "444d64da"
      },
      "source": [
        "9)\n",
        "Inspect the tagged corpus, what types of tags do you see?\n",
        "What do they mean?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "2eb45e2f",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2eb45e2f",
        "outputId": "7ca4a00b-7410-4dce-d40c-68a00d140dba"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['',\n",
              " 'NNP = proper noun',\n",
              " 'RB = adverb',\n",
              " 'VBD = verb, past tense took',\n",
              " 'JJ = adjective',\n",
              " 'NNS = noun plural',\n",
              " 'VBP = verb, sing. present',\n",
              " 'NN = noun',\n",
              " 'VBZ =verb, 3rd person sing. present',\n",
              " 'VBG = verb, gerund/present participle',\n",
              " 'MD = modal',\n",
              " '']"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "\n",
        "tags_name =\"\"\"\n",
        "NNP = proper noun\n",
        "RB = adverb\n",
        "VBD = verb, past tense took\n",
        "JJ = adjective\n",
        "NNS = noun plural\n",
        "VBP = verb, sing. present\n",
        "NN = noun\n",
        "VBZ =verb, 3rd person sing. present\n",
        "VBG = verb, gerund/present participle\n",
        "MD = modal\n",
        "\"\"\"\n",
        "tags_name.split(\"\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dynamic-excess",
      "metadata": {
        "id": "dynamic-excess"
      },
      "source": [
        "Here follows an example with a short sentence to introduce chunking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "noted-english",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "noted-english",
        "outputId": "9d226356-1e1b-444a-ff0d-214e4f7c49ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(GPE Israeli/JJ)\n",
            "(PERSON Ehud/NNP Olmert/NNP)\n",
            "(GPE Palestinian/NNP)\n",
            "(PERSON Mahmoud/NNP Abbas/NNP)\n",
            "(GPE Jerusalem/NNP)\n",
            "(GPE Palestinian/JJ)\n",
            "(PERSON Saeb/NNP Erekat/NNP)\n",
            "(GPE Israeli/JJ)\n",
            "(GPE Palestinian/JJ)\n",
            "(PERSON Mr./NNP Olmert/NNP)\n",
            "(PERSON Mr./NNP Olmert/NNP)\n",
            "(ORGANIZATION Kadima/NNP Party/NNP)\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "sent = (\"Israeli Prime Minister Ehud Olmert is scheduled to meet with Palestinian President Mahmoud Abbas Wednesday in Jerusalem. Palestinian negotiator Saeb Erekat said the talks will focus on permanent- status issues, Israeli checkpoints and the fate of Palestinian prisoners. The meeting, at Mr. Olmert's official residence, will be the first between the two since Mr. Olmert announced that he will step down after his Kadima Party chooses a new leader in September. The two leaders re-started peace talks in November with the goal of reaching a deal by this year's end\")\n",
        "\n",
        "# Tokenisation\n",
        "tokenised = nltk.word_tokenize(sent)\n",
        "\n",
        "# Taggning\n",
        "tagged = nltk.pos_tag(tokenised)\n",
        "\n",
        "# Chunking\n",
        "sentChunked = nltk.ne_chunk(tagged)\n",
        "\n",
        "#PERSON, ORGANIZATION and GPE\n",
        "\n",
        "#Print some named entities in the sentence\n",
        "for n in sentChunked:\n",
        "    if isinstance(n, nltk.tree.Tree):               \n",
        "        if n.label() == 'PERSON' or n.label() == 'ORGANIZATION' or n.label() == 'GPE':\n",
        "            print(n)\n",
        "        else: \n",
        "            n\n",
        "            #print(n)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "instrumental-arcade",
      "metadata": {
        "id": "instrumental-arcade"
      },
      "source": [
        "Use the function draw() to draw a chunktree (shallow parse tree),"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('classic')\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "YKNF1MaRCzx9"
      },
      "id": "YKNF1MaRCzx9",
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "nonprofit-torture",
      "metadata": {
        "id": "nonprofit-torture"
      },
      "outputs": [],
      "source": [
        "if not IN_COLAB:\n",
        "  sentChunked.draw()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "undefined-intermediate",
      "metadata": {
        "id": "undefined-intermediate"
      },
      "source": [
        "10)\n",
        "Count the number of Persons, Organisation and GPEs, Geo Political Entities in the BBC corpus. Follow the above example and extend the function.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eligible-replication",
      "metadata": {
        "id": "eligible-replication"
      },
      "source": [
        "The chunking of the BBC corpus takes some time, please be patient."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "devoted-runner",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "devoted-runner",
        "outputId": "7dd86050-a040-4da8-f11e-31d829b730fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chunking\n"
          ]
        }
      ],
      "source": [
        "print('Chunking')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "expanded-publisher",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "expanded-publisher",
        "outputId": "d8131103-fdf0-4425-a897-5451c1a50828"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 16.2 s, sys: 38.5 ms, total: 16.2 s\n",
            "Wall time: 16.8 s\n"
          ]
        }
      ],
      "source": [
        "# Chunking\n",
        "%time chuncked_bbc = nltk.ne_chunk(tagged_txt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "33f0e1e4",
      "metadata": {
        "id": "33f0e1e4"
      },
      "outputs": [],
      "source": [
        "persons = 0\n",
        "organizations= 0\n",
        "gpe_location = 0\n",
        "for n in chuncked_bbc:\n",
        "    if isinstance(n, nltk.tree.Tree):               \n",
        "        if n.label() == 'PERSON':\n",
        "            persons +=1\n",
        "        if n.label() == 'ORGANIZATION':\n",
        "            organizations+=1\n",
        "        if n.label() == 'GPE':\n",
        "            gpe_location+=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "complex-blackberry",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "complex-blackberry",
        "outputId": "c36a6cc8-5b75-45fa-9082-94771d4edc8c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2321"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "# Number of PERSON\n",
        "persons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "photographic-settle",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "photographic-settle",
        "outputId": "3e38ad62-a278-4291-848c-00d6917b97b0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1015"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "# Number of ORGANIZATION\n",
        "organizations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "norwegian-papua",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "norwegian-papua",
        "outputId": "05e3b857-cdda-4742-e493-3663dd92ea05"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1022"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "# Number of GPE/locations\n",
        "gpe_location"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "applicable-tours",
      "metadata": {
        "id": "applicable-tours"
      },
      "source": [
        "### Now we will study N-grams\n",
        "See example below, fill in the missing code.\n",
        "\n",
        "11) Are there any bigrams or trigram or ngrams that give\n",
        "logical groups of texts/grams?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "continuing-engineer",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "continuing-engineer",
        "outputId": "0e67cae7-824e-4c01-a794-2f04172b740f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('Israeli', 'Prime', 'Minister')\n",
            "('Prime', 'Minister', 'Ehud')\n",
            "('Minister', 'Ehud', 'Olmert')\n",
            "('Ehud', 'Olmert', 'is')\n",
            "('Olmert', 'is', 'scheduled')\n",
            "('is', 'scheduled', 'to')\n",
            "('scheduled', 'to', 'meet')\n",
            "('to', 'meet', 'with')\n",
            "('meet', 'with', 'Palestinian')\n",
            "('with', 'Palestinian', 'President')\n",
            "('Palestinian', 'President', 'Mahmoud')\n",
            "('President', 'Mahmoud', 'Abbas')\n",
            "('Mahmoud', 'Abbas', 'Wednesday')\n",
            "('Abbas', 'Wednesday', 'in')\n",
            "('Wednesday', 'in', 'Jerusalem')\n",
            "('in', 'Jerusalem', '.')\n",
            "('Jerusalem', '.', 'Palestinian')\n",
            "('.', 'Palestinian', 'negotiator')\n",
            "('Palestinian', 'negotiator', 'Saeb')\n",
            "('negotiator', 'Saeb', 'Erekat')\n",
            "('Saeb', 'Erekat', 'said')\n",
            "('Erekat', 'said', 'the')\n",
            "('said', 'the', 'talks')\n",
            "('the', 'talks', 'will')\n",
            "('talks', 'will', 'focus')\n",
            "('will', 'focus', 'on')\n",
            "('focus', 'on', 'permanent-')\n",
            "('on', 'permanent-', 'status')\n",
            "('permanent-', 'status', 'issues')\n",
            "('status', 'issues', ',')\n",
            "('issues', ',', 'Israeli')\n",
            "(',', 'Israeli', 'checkpoints')\n",
            "('Israeli', 'checkpoints', 'and')\n",
            "('checkpoints', 'and', 'the')\n",
            "('and', 'the', 'fate')\n",
            "('the', 'fate', 'of')\n",
            "('fate', 'of', 'Palestinian')\n",
            "('of', 'Palestinian', 'prisoners')\n",
            "('Palestinian', 'prisoners', '.')\n",
            "('prisoners', '.', 'The')\n",
            "('.', 'The', 'meeting')\n",
            "('The', 'meeting', ',')\n",
            "('meeting', ',', 'at')\n",
            "(',', 'at', 'Mr.')\n",
            "('at', 'Mr.', 'Olmert')\n",
            "('Mr.', 'Olmert', \"'s\")\n",
            "('Olmert', \"'s\", 'official')\n",
            "(\"'s\", 'official', 'residence')\n",
            "('official', 'residence', ',')\n",
            "('residence', ',', 'will')\n",
            "(',', 'will', 'be')\n",
            "('will', 'be', 'the')\n",
            "('be', 'the', 'first')\n",
            "('the', 'first', 'between')\n",
            "('first', 'between', 'the')\n",
            "('between', 'the', 'two')\n",
            "('the', 'two', 'since')\n",
            "('two', 'since', 'Mr.')\n",
            "('since', 'Mr.', 'Olmert')\n",
            "('Mr.', 'Olmert', 'announced')\n",
            "('Olmert', 'announced', 'that')\n",
            "('announced', 'that', 'he')\n",
            "('that', 'he', 'will')\n",
            "('he', 'will', 'step')\n",
            "('will', 'step', 'down')\n",
            "('step', 'down', 'after')\n",
            "('down', 'after', 'his')\n",
            "('after', 'his', 'Kadima')\n",
            "('his', 'Kadima', 'Party')\n",
            "('Kadima', 'Party', 'chooses')\n",
            "('Party', 'chooses', 'a')\n",
            "('chooses', 'a', 'new')\n",
            "('a', 'new', 'leader')\n",
            "('new', 'leader', 'in')\n",
            "('leader', 'in', 'September')\n",
            "('in', 'September', '.')\n",
            "('September', '.', 'The')\n",
            "('.', 'The', 'two')\n",
            "('The', 'two', 'leaders')\n",
            "('two', 'leaders', 're-started')\n",
            "('leaders', 're-started', 'peace')\n",
            "('re-started', 'peace', 'talks')\n",
            "('peace', 'talks', 'in')\n",
            "('talks', 'in', 'November')\n",
            "('in', 'November', 'with')\n",
            "('November', 'with', 'the')\n",
            "('with', 'the', 'goal')\n",
            "('the', 'goal', 'of')\n",
            "('goal', 'of', 'reaching')\n",
            "('of', 'reaching', 'a')\n",
            "('reaching', 'a', 'deal')\n",
            "('a', 'deal', 'by')\n",
            "('deal', 'by', 'this')\n",
            "('by', 'this', 'year')\n",
            "('this', 'year', \"'s\")\n",
            "('year', \"'s\", 'end')\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk import bigrams,trigrams\n",
        "sent = (\"Israeli Prime Minister Ehud Olmert is scheduled to meet with Palestinian President Mahmoud Abbas Wednesday in Jerusalem. Palestinian negotiator Saeb Erekat said the talks will focus on permanent- status issues, Israeli checkpoints and the fate of Palestinian prisoners. The meeting, at Mr. Olmert's official residence, will be the first between the two since Mr. Olmert announced that he will step down after his Kadima Party chooses a new leader in September. The two leaders re-started peace talks in November with the goal of reaching a deal by this year's end\")\n",
        "tokenised = nltk.word_tokenize(sent)\n",
        "grams = trigrams(tokenised)\n",
        "for gram in grams:\n",
        "  print(gram)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "material-fault",
      "metadata": {
        "id": "material-fault"
      },
      "source": [
        "### Now we will do some regular expression matching"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "inside-gossip",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "inside-gossip",
        "outputId": "b8fef877-ac17-4cc4-da7b-e21cd926a55d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Sweden',\n",
              " 'Sweden',\n",
              " 'Sweden',\n",
              " 'Sweden',\n",
              " 'Sweden',\n",
              " 'Sweden',\n",
              " 'Sweden',\n",
              " 'Sweden',\n",
              " 'Sweden']"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "# Import regular expression library for Python\n",
        "import re\n",
        "\n",
        "# Match all Sweden in the corpusText\n",
        "re.findall(r\"Sweden\", corpusText)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "unusual-relief",
      "metadata": {
        "id": "unusual-relief"
      },
      "source": [
        "Do the same for Sweden again but extract also the snippet/text around them. \n",
        "\n",
        "12) What do you see?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "neither-prediction",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "neither-prediction",
        "outputId": "50c6be13-c55d-4a5a-8fd0-24e6bb34d283"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['the UK third behind Sweden and Ireland for bus',\n",
              " 'ly, Switzerland and Sweden will be stored perm',\n",
              " 'l sides of Ireland, Sweden and Norway. Shares ',\n",
              " 'end up producing in Sweden?\"',\n",
              " ' build Cadillacs in Sweden',\n",
              " 'ing Saab factory in Sweden.',\n",
              " 'lloyed good news in Sweden, since it reflects ',\n",
              " ' American marque in Sweden is part of its effo',\n",
              " 'illac production to Sweden should help introdu']"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "re.findall(\".{0,20}Sweden.{0,20}\", corpusText)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "august-lyric",
      "metadata": {
        "id": "august-lyric"
      },
      "source": [
        "Do the same for the car company SAAB but extract also the snippet/text around them. \n",
        "\n",
        "13) What do you see?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "academic-ribbon",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "academic-ribbon",
        "outputId": "2465874a-f1be-4125-ee28-8b8e3a291107"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['pean units Opel and Saab have both had troub',\n",
              " 'Saab to build Cadillacs ',\n",
              " ' at its loss-making Saab factory in Sweden.',\n",
              " \" allay fears of the Saab factory's closure. \",\n",
              " \", since it reflects Saab's failure to make s\",\n",
              " ' market. For years, Saab has consistently sa',\n",
              " 'needed scale to the Saab factory, which curr',\n",
              " 'ble operations, and Saab is losing money fas',\n",
              " 'nditure by building Saabs, Opels - badged as',\n",
              " \"y to further reduce Saab's losses could be t\",\n",
              " 'f the production of Saabs to the US, a marke',\n",
              " 'ar, which is making Saabs more expensive to ']"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "re.findall(\".{0,20}Saab.{0,20}\", corpusText)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dramatic-samba",
      "metadata": {
        "id": "dramatic-samba"
      },
      "source": [
        "Combine the two regular expressions so get both Sweden and Saab in the same context.\n",
        "\n",
        "14) Are the results comprehensible? How can you improve them?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "worthy-collar",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "worthy-collar",
        "outputId": "86ec3528-e8f3-4cae-8d7f-6ebff1bdce05"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"Sweden, since it reflects Saab's failure to make significant inroads into the lucrative European luxury car market. For years, Saab has consistently sa\",\n",
              " \"Sweden should help introduce desperately-needed scale to the Saab factory, which currently produces fewer than 130,000 cars per year. That is about half of what major car makers consider sufficient numbers for profitable operations, and Saab is losing money fast - albeit with losses halved in 2004 to $200m (£104m; 151m euros) from $500m the previous year. Beyond the 12,000 job cuts announced last year at its European operations, GM is reducing expenditure by building Saabs, Opels - badged as Vauxhalls in the UK - and now Cadillacs on the same framework, and by allowing the different brands to share parts. Another way to further reduce Saab's losses could be to shift some of the production of Saabs to the US, a market where drivers have adopted it as an upmarket European car. Doing so would remove the exposure to the weak US dollar, which is making Saabs more expensive to \"]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "re.findall(\"Sweden.*Saab.{0,20}\", corpusText)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "waiting-dynamics",
      "metadata": {
        "id": "waiting-dynamics"
      },
      "source": [
        "### Here is an extra task which is not compulsary.\n",
        "Match all organisations that is close to Sweden in the BBC corpus and print the snippets.\n",
        "\n",
        "15) What do you get? Are there repetitions? How can one avoid them?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "essential-scientist",
      "metadata": {
        "id": "essential-scientist"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "name": "nlplab1.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}